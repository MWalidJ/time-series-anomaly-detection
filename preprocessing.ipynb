{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGBWGOUAvNyFU+FM6qjTft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MWalidJ/time-series-anomaly-detection/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is an example of how to make a one recording loading"
      ],
      "metadata": {
        "id": "JXjCEU3UWWWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'your_eeg_file.edf' is the path to your EEG file\n",
        "raw = mne.io.read_raw_edf('your_eeg_file.edf', preload=True)\n",
        "sampling_rate = raw.info['sfreq']\n",
        "duration = 23.6  # seconds\n",
        "n_samples = int(sampling_rate * duration)\n",
        "\n",
        "# Get the data (channels x time points)\n",
        "eeg_data = raw.get_data()\n",
        "\n",
        "# Get the data for the first 'sample' (first 23.6 seconds)\n",
        "one_sample_data = eeg_data[:, :n_samples]\n"
      ],
      "metadata": {
        "id": "z8mctaguWUKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to work on all data.\n",
        "\n",
        "This this an example for the steps of:\n",
        "\n",
        "1- load data\n",
        "2-preprocessing\n",
        "3-segmenting"
      ],
      "metadata": {
        "id": "6t2j2mz-BweP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owJOlXlYBmD8"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def preprocess_eeg(file_path, selected_channels=None, sfreq=256, l_freq=1.0, h_freq=40.0):\n",
        "    \"\"\"\n",
        "    Load and preprocess EEG file: filtering, resampling, normalization.\n",
        "\n",
        "    Args:\n",
        "        file_path: path to .edf EEG file\n",
        "        selected_channels: list of channel names to pick (optional)\n",
        "        sfreq: target sampling frequency\n",
        "        l_freq: low frequency cut-off for bandpass filter\n",
        "        h_freq: high frequency cut-off for bandpass filter\n",
        "\n",
        "    Returns:\n",
        "        preprocessed_data: np.array of shape (channels, samples)\n",
        "    \"\"\"\n",
        "    # Load raw EEG\n",
        "    raw = mne.io.read_raw_edf(file_path, preload=True)\n",
        "\n",
        "    # Pick desired channels (optional)\n",
        "    if selected_channels is not None:\n",
        "        raw.pick_channels(selected_channels)\n",
        "\n",
        "    # Bandpass filter\n",
        "    raw.filter(l_freq=l_freq, h_freq=h_freq)\n",
        "\n",
        "    # Resample\n",
        "    raw.resample(sfreq)\n",
        "\n",
        "    # Get data\n",
        "    data = raw.get_data()  # shape: [channels, samples]\n",
        "\n",
        "    # Z-score normalization per channel\n",
        "    data = (data - data.mean(axis=1, keepdims=True)) / (data.std(axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "    return data\n",
        "\n",
        "def segment_eeg(data, sfreq=256, window_sec=2, overlap=0.5):\n",
        "    \"\"\"\n",
        "    Segment preprocessed EEG into overlapping windows.\n",
        "\n",
        "    Args:\n",
        "        data: np.array of shape (channels, samples)\n",
        "        sfreq: sampling frequency\n",
        "        window_sec: window size in seconds\n",
        "        overlap: fraction of overlap between windows\n",
        "\n",
        "    Returns:\n",
        "        segments: np.array of shape (num_windows, channels, window_size)\n",
        "    \"\"\"\n",
        "    n_channels, n_samples = data.shape\n",
        "    window_size = int(window_sec * sfreq)\n",
        "    step_size = int(window_size * (1 - overlap))\n",
        "\n",
        "    segments = []\n",
        "    for start_idx in range(0, n_samples - window_size + 1, step_size):\n",
        "        end_idx = start_idx + window_size\n",
        "        window = data[:, start_idx:end_idx]\n",
        "        segments.append(window)\n",
        "\n",
        "    segments = np.stack(segments, axis=0)\n",
        "    return segments\n",
        "\n",
        "# Example Usage:\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Parameters\n",
        "    filepath = 'path/to/your/eeg_file.edf'  # <-- Update this\n",
        "    selected_channels = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T3', 'C3', 'Cz', 'C4', 'T4', 'T5', 'P3', 'Pz', 'P4', 'T6', 'O1', 'O2']\n",
        "    window_sec = 2\n",
        "    overlap = 0.5\n",
        "    target_sfreq = 256\n",
        "\n",
        "    # Preprocess\n",
        "    data = preprocess_eeg(filepath, selected_channels, sfreq=target_sfreq)\n",
        "\n",
        "    # Segment\n",
        "    segments = segment_eeg(data, sfreq=target_sfreq, window_sec=window_sec, overlap=overlap)\n",
        "\n",
        "    print(f\"Final segmented data shape: {segments.shape}\")\n",
        "    # Example output: (num_windows, 19, 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now, the questions needed to be answered\n",
        "\n",
        "1.   Do we need to select channels and drop out others?\n (not an answer but we should note that the naming of channels might be different and that not all channels are included for all subjects or we might even have some corrupted channels)\n",
        "2.   Do we need to filter frequency?\n (for this we might need to do frequency analysis and time-frequency spectral analysis\n)",
        "3.   What is the sample rate ( I have read that the standard is 256 but we have to look more in the papers how did they select and what is the rate they used )\n",
        "4.   What is the overlapping for the windows? maybe we can start with 0.5?\n",
        "5.   select the windows time (1,2,3,4,5 seconds?) # timesteps(samples) per window = window number of secs * number of Hz(sample rate)\n",
        "6.   \n",
        "please walid add more if you have any question in your mind\n"
      ],
      "metadata": {
        "id": "bwcOv8O9CPkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "now that we have preprocessed the data, we need a dataloader to allow ( batching, shuffling, parallizing ) for the dataset in order to feed the model.\n",
        "\n",
        "I have read that for large datasets such as ours, typical dataloading loads all files at once, which can overwhelm the RAM and make it crash.\n",
        "\n",
        "Thus, a technique called \"Lazy Loading\" is used to load only data that are called (loading on-demand)\n"
      ],
      "metadata": {
        "id": "PJdexvdwJVLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class EEGWindowLazyDataset(Dataset):\n",
        "    def __init__(self, data_folder, window_shape, transform=None):\n",
        "        \"\"\"\n",
        "        Lazy-loading EEG dataset. Loads one window at a time from file.\n",
        "\n",
        "        Args:\n",
        "            data_folder: Path to folder containing .npy segment files\n",
        "            window_shape: (channels, samples)\n",
        "            transform: Optional transform function\n",
        "        \"\"\"\n",
        "        self.data_folder = data_folder\n",
        "        self.window_shape = window_shape\n",
        "        self.transform = transform\n",
        "\n",
        "        # Index all segments individually, not per file\n",
        "        self.index = []\n",
        "\n",
        "        for file_name in os.listdir(data_folder):\n",
        "            if file_name.endswith('.npy'):\n",
        "                file_path = os.path.join(data_folder, file_name)\n",
        "                # Get number of segments in this file\n",
        "                segments = np.load(file_path, mmap_mode='r')  # mmap_mode --> do NOT fully load!\n",
        "                num_segments = segments.shape[0]\n",
        "                for i in range(num_segments):\n",
        "                    self.index.append((file_path, i))  # Save (file_path, segment_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, segment_idx = self.index[idx]\n",
        "        # Load just the needed window\n",
        "        segments = np.load(file_path, mmap_mode='r')\n",
        "        window = segments[segment_idx]  # shape: (channels, samples)\n",
        "\n",
        "        if self.transform:\n",
        "            window = self.transform(window)\n",
        "\n",
        "        window = torch.tensor(window, dtype=torch.float32)\n",
        "        window = window.permute(1, 0)  # Now [samples, channels] for xLSTM\n",
        "\n",
        "        return window\n",
        "\n",
        "def create_lazy_eeg_dataloader(data_folder, window_shape, batch_size=32, shuffle=True, num_workers=4):\n",
        "    dataset = EEGWindowLazyDataset(data_folder, window_shape)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
        "    return loader\n"
      ],
      "metadata": {
        "id": "dqRAhCoJMc0i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
